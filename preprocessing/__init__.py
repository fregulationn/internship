# -*- coding: utf-8 -*-
"""
-------------------------------------------------
   File Nameï¼š     __init__.py
   Author :       peng.he
-------------------------------------------------
"""
import jieba
import pandas as pd
from sklearn.preprocessing import LabelEncoder

RANDOM_SEED = 2018
NGRAM = 2


def split_text(texts, ngram=1):
    results = []
    for t in texts:
        # split text according to jieba segmentation
        seg_words = []
        for w in jieba.cut(t):
            seg_words.append(w)
        seg_txt = u' '.join(seg_words)
        # split text according to ngram
        txt_list = [seg_txt]
        for n in range(1, ngram + 1):
            char = u' '.join([t[c_i:c_i + n] for c_i in range(len(t) - n + 1)])
            txt_list.append(char)
        txt = u' '.join(txt_list)
        results.append(txt)
    return results


def _train_count_vector(data):
    from sklearn.feature_extraction.text import CountVectorizer
    count_vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 2))
    count_vectorizer.fit(data)
    return count_vectorizer


def _get_raw_df(file):
    '''
    columns:[sentence,label,file_name]
    :param file: 
    :return: 
    '''
    print('load raw data from {}'.format(file))
    df = pd.read_excel(file)
    return df


def get_data(file):
    df = _get_raw_df(file)

    df['raw_label'] = df.label
    df['split'] = split_text(df.sentence, NGRAM)

    c_v = _train_count_vector(df.split)

    le = LabelEncoder()
    df.label = le.fit_transform(df.label)

    X = c_v.transform(df.split)
    y = df.label
    return X, y, le, c_v


__all__ = ['get_data']
